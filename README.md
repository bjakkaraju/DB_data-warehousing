# Databricks SQL in Action: Intelligent Data Warehousing, Analytics and BI Hands-On Lab

This workshop guide is broken up into 2 major sections:

* Administrator POV (Data Architect, Data Warehousing Architect, Database Administrator, etc.) of Databricks SQL and the
* User POV (Data Analyst, Business Analyst, SQL Analyst, etc)

# Part 1: Navigating Databricks SQL as a Workspace Administrator
* Step 0: Configure SQL Warehouse
* Step 1: Create a catalog and catalog name
* Step 2: Create a schema/database and schema/database name
* Step 3: Create a volume
* Step 4: Create streaming tables
* Step 5: Create materialized views
* Step 6: Creating primary and foreign key constraints
* Step 7: Viewing query history and query profile
* Step 8: Creating AI-Generated documentation of data assets
* Step 9: Setting permissions on data assets

# Part 2: Navigating Databricks SQL as a Workspace User
* Step 1: Create an AI/BI Dashboard
* Step 2: Publish and Share an AI/BI Dashboard
* Step 3: Create an AI/BI Genie
* Step 4: Publish and Share an AI/BI Genie
* Step 5: Monitoring AI/BI Genie
* Step 6: Evaluating AI/BI Genie
* Step 7: View the Entity Relationship Diagram (ERD)
* Step 8: View Data Lineage

# üöÄ Prerequisites
No prior data warehousing, analytics or governance experience required! This tutorial is designed for developers who want to learn data & AI fundamentals.

1. Free Databricks Account
Sign up at databricks.com/learn/free-edition
No credit card required, free forever
Includes Apache Spark, Delta Lake, and Unity Catalog
15GB storage with community support

2. Sample Data (Provided)
Use our airports.csv, lookupcodes.csv and flights.csv (Note: Flights CSV was such a large file it had to be placed in the release notes)

# üõ†Ô∏è Quick Start
Get up and running in 10 minutes:

* Sign up for free account
* Create new workspace
* Download the Required Files

From this repository, download:
* Airports CSV File
* Lookupcodes CSV File
* Flights CSV File (can be found in the release notes)

Follow step-by-step instructions in the admin.md file and then the user.md file

Build your first data lakehouse!
